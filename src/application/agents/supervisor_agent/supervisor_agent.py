from application.agents.extras import State, Router, GraphCallback
from application.agents.tools.query_dbutils import create_pinecone_tool
from application.dbutils import DbUtils
from application.environment import Environment
from application.api.models.permission import Permission

from langchain_core.messages import HumanMessage
from langgraph.prebuilt import create_react_agent
from langgraph.graph import START, END, StateGraph
from langgraph.types import Command
from typing import Literal, Optional
from langchain_mistralai import ChatMistralAI

class SupervisorAgent:
        
    def __init__(self, env: Environment, dbutils: DbUtils):
        self.context_limit = 0
        self.gen_limit = 0
        self.pinecone_tool = create_pinecone_tool(dbutils)
        self.members = ["gen", "context"]
        self.options = self.members + ["FINISH"]
        self.genclient = ChatMistralAI(
            model="mistral-large-latest",
            temperature=0,
            max_retries=2,
            max_tokens = 500,
            api_key = env.DEEPSEEK_API_KEY,
            callbacks=[GraphCallback()]
        )

        self.system_prompt = (
            f"You are a supervisor that manages a conversation between the following workers: {self.members}. " 
            "Given a user request, respond with which worker to go to next. The workers respond with their results and status. " 
            "When you get any answer, respond with FINISH."
            "The first time around, use the context node."
        )

        # MOVE THESE
        # NEED PROPER TOOLS FOR THESE
        self.gen_agent = create_react_agent(
            self.genclient,
            tools=[],
            prompt=f"Your sole purpose is to read in the facts generated by another agent, and then format it into a answer."
                    "Do not make up your own facts, you will only use the facts provided. Format it as plaintext not markdown." 
                    "Afterwards, mention which namespaces were used. Format it this way: Namespace(s) used: then the namespace name. If no namespaces are present, then format this way, Namespace(s) used: None."
        )
        
        self.context_agent = create_react_agent(
            self.genclient, 
            tools=[self.pinecone_tool],
            prompt=f"Your sole purpose is to fetch context from a pinecone database." 
                    "The user permissions defined in the query are the namespaces you are allowed to access."
                    "Only use namespaces that are in the original query."
                    "If the user does not have any permissions, do not try to make up answers or hit random namespaces. Tell them they do not have any permissions"
                    "Use your tool with these namespaces to retrieve context"
                    "Always keep track of the namespaces used. Always carry over the namspaces used, even if the namespace was used once."
                    "Format that metadata into facts."
                    "Add the namespaces used into the facts."
                    "You do not answer the question, just format the data into basic facts."
                    "When you have the facts organised, just return the facts."
                    "If you cannot fetch any context, do not make things up."
        )
        
        self.build_graph()

    def build_graph(self) -> None:
        builder = StateGraph(State)
        builder.add_edge(START, "supervisor")
        builder.add_node("supervisor", self.supervisor)
        builder.add_node("context", self.context)
        builder.add_node("gen", self.gen)
        builder.add_edge("gen", END)
        
        self.graph = builder.compile()        
    
    def context(self, state: State) -> Command[Literal["supervisor"]]:
        result = self.context_agent.invoke(state)
        print(result["messages"][-1].pretty_print())

        return Command(
            update={
            "messages": [
                HumanMessage(content=result["messages"][-1].content, name="context")
            ]
            },
        goto="supervisor"
        )

    def gen(self, state: State) -> Command[Literal["supervisor"]]:
        result = self.gen_agent.invoke(state)
        print(result["messages"][-1].pretty_print())        

        return Command(
            update={
            "messages": [
                HumanMessage(content=result["messages"][-1].content, name="gen")
            ]
            },
        goto="supervisor"
        )

    def supervisor(self, state: State) -> Command[Literal["context", "gen", "__end__"]]:
        # some boilerplate
        # we format this in a way that ChatMistralAI can understand, look at its langchain page to see
        messages = [
        {
            "role": "system",
            "content": self.system_prompt,
        }, 
        ] + state["messages"]
        # if we have reached the context limit, force a finish state
        if self.context_limit == 3 or self.gen_limit == 3:
            # cant finish till we call each node at least once
            # TODO rewrite this!!!!
            # Im putting a ticket for this, its eternally annoying me
            if self.gen_limit < 1:
                self.gen_limit += 1
                return Command(goto="gen", update={"next": "gen"})
            if self.context_limit < 1:
                self.context_limit += 1
                return Command(goto="context", update={"next": "context"})
            return Command(goto=END, update={"next": END})

        # here, we pass the state and our first prompt to the genclient (which will decide what to do next)
        # we pass it the router, which tells the agent what options it has, and give it the messages, 
        # which includes its prompt and the global state 
        response = self.genclient.with_structured_output(Router).invoke(messages)
        # decides where to go next, we are done if genclient told us to stop
        goto = response["next"]
        if goto == "FINISH":
            # we cant finish until we have called each node at least once
            if self.context_limit > 0 and self.gen_limit > 0:
                goto = END
            else:
                goto = "gen" if self.gen_limit < self.context_limit else "context"
        
        # check if we are hitting the context node too many times
        if goto == "context":
            self.context_limit += 1
        
        if goto == "gen":
            self.gen_limit += 1
        # Command is used to move to different nodes
        return Command(goto=goto, update={"next": goto})

    def take_input(self, user_message: str, user_permissions: list[Permission]) -> Optional[str]:
        previous_step = None
        print(str([perm.permission_name for perm in user_permissions]))
        for step in self.graph.stream({
            "messages" : [(
                "user", "Here is the user query: " + user_message + ". Here are the users permissions: " + str([perm.permission_name for perm in user_permissions])
        )]
        }, subgraphs=True):
            if "gen" in step[1]:
                messages = step[1]["gen"]["messages"]
                previous_step = messages[0].content

            if "supervisor" in step[1]:
                if END in step[1]["supervisor"]["next"]:
                    self.context_limit = 0
                    self.gen_limit = 0
                    print(previous_step)
                    return previous_step
